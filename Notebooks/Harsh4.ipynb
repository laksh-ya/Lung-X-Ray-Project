{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed2cc5-fdee-4b66-bc8a-e53938f6a141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thebe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 184ms/step - accuracy: 0.7188 - loss: 0.6094 - val_accuracy: 0.8602 - val_loss: 0.4991 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 158ms/step - accuracy: 0.8337 - loss: 0.3747 - val_accuracy: 0.8737 - val_loss: 0.3478 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 163ms/step - accuracy: 0.8694 - loss: 0.3414 - val_accuracy: 0.8752 - val_loss: 0.3503 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - accuracy: 0.8744 - loss: 0.3039 - val_accuracy: 0.8707 - val_loss: 0.3068 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step - accuracy: 0.8932 - loss: 0.2644 - val_accuracy: 0.8872 - val_loss: 0.2572 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 159ms/step - accuracy: 0.9139 - loss: 0.2371 - val_accuracy: 0.8977 - val_loss: 0.2660 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 161ms/step - accuracy: 0.9074 - loss: 0.2397 - val_accuracy: 0.8827 - val_loss: 0.3208 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 159ms/step - accuracy: 0.9275 - loss: 0.1874 - val_accuracy: 0.8962 - val_loss: 0.3087 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 103ms/step - accuracy: 0.9422 - loss: 0.1693 - val_accuracy: 0.8977 - val_loss: 0.2641 - learning_rate: 0.0050\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step - accuracy: 0.9366 - loss: 0.1664 - val_accuracy: 0.8992 - val_loss: 0.2785 - learning_rate: 0.0050\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 103ms/step - accuracy: 0.9477 - loss: 0.1554 - val_accuracy: 0.9008 - val_loss: 0.2765 - learning_rate: 0.0050\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - accuracy: 0.9475 - loss: 0.1438 - val_accuracy: 0.9008 - val_loss: 0.3009 - learning_rate: 0.0025\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 159ms/step - accuracy: 0.9569 - loss: 0.1107 - val_accuracy: 0.9098 - val_loss: 0.2909 - learning_rate: 0.0025\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91       418\n",
      "           1       0.83      0.87      0.85       247\n",
      "\n",
      "    accuracy                           0.89       665\n",
      "   macro avg       0.88      0.88      0.88       665\n",
      "weighted avg       0.89      0.89      0.89       665\n",
      "\n",
      "Accuracy: 0.8872180451127819\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Data Loading with Augmentation\n",
    "base_path = '../Database/'\n",
    "data, labels = [], []\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2], fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load Data\n",
    "def load_images_from_folder(folder, label):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "load_images_from_folder(\"Normal\", \"Normal\")\n",
    "for folder in [\"Lung_Opacity\", \"Viral Pneumonia\"]:\n",
    "    load_images_from_folder(folder, \"Lung_Disease\")\n",
    "\n",
    "data = np.array(data).astype('float32') / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "\n",
    "# Extract HOG Features\n",
    "def extract_hog_features(images):\n",
    "    return np.array([hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2), visualize=False) for img in images])\n",
    "\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_test_hog = extract_hog_features(X_test)\n",
    "\n",
    "# Combine CNN + HOG Features\n",
    "X_train_combined = np.hstack((X_train.reshape(X_train.shape[0], -1), X_train_hog))\n",
    "X_test_combined = np.hstack((X_test.reshape(X_test.shape[0], -1), X_test_hog))\n",
    "\n",
    "# Handle Imbalance Using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_combined, y_train = smote.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "# Custom Dense Model (for combined features)\n",
    "def create_custom_dense_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(input_shape,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model Initialization\n",
    "model = create_custom_dense_model(X_train_combined.shape[1])\n",
    "\n",
    "# Learning Rate Scheduler & Early Stopping\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_combined, y_train, validation_data=(X_test_combined, y_test),\n",
    "                    epochs=50, callbacks=[lr_scheduler, early_stopping], batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = (model.predict(X_test_combined) > 0.5).astype(\"int32\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# LIME Explanation\n",
    "# Modify LIME explanation\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_train_combined,\n",
    "    feature_names=[\"Feature \" + str(i) for i in range(X_train_combined.shape[1])],\n",
    "    class_names=[\"Normal\", \"Lung_Disease\"],\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# Function to make LIME-compatible predictions\n",
    "def lime_predict_fn(x):\n",
    "    preds = model.predict(x)  # Model returns shape (n_samples, 1)\n",
    "    return np.hstack([1 - preds, preds])  # Convert to shape (n_samples, 2)\n",
    "\n",
    "# Explain a test instance\n",
    "exp = explainer.explain_instance(X_test_combined[0], lime_predict_fn, num_features=10)\n",
    "\n",
    "# Show explanation\n",
    "exp.as_pyplot_figure()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training & Validation Graphs\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da7a7b-b136-4cb7-b46c-eeebed04245c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974977a-3411-40ce-8002-a882f638c1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
