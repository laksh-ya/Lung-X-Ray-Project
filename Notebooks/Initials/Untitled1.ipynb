{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706bd8fa-3b97-486f-9141-be366ad7b79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thebe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 182ms/step - accuracy: 0.6466 - loss: 0.6873 - val_accuracy: 0.8436 - val_loss: 0.4059 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 144ms/step - accuracy: 0.8042 - loss: 0.4523 - val_accuracy: 0.8707 - val_loss: 0.3466 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 149ms/step - accuracy: 0.8444 - loss: 0.3878 - val_accuracy: 0.8767 - val_loss: 0.3084 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - accuracy: 0.8654 - loss: 0.3235 - val_accuracy: 0.8932 - val_loss: 0.2671 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 146ms/step - accuracy: 0.8759 - loss: 0.3140 - val_accuracy: 0.8887 - val_loss: 0.2643 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - accuracy: 0.8921 - loss: 0.2702 - val_accuracy: 0.8977 - val_loss: 0.2503 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 139ms/step - accuracy: 0.9175 - loss: 0.2280 - val_accuracy: 0.8977 - val_loss: 0.2535 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 144ms/step - accuracy: 0.9151 - loss: 0.2156 - val_accuracy: 0.8932 - val_loss: 0.2757 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 144ms/step - accuracy: 0.9253 - loss: 0.1964 - val_accuracy: 0.8947 - val_loss: 0.2707 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 151ms/step - accuracy: 0.9308 - loss: 0.1937 - val_accuracy: 0.9098 - val_loss: 0.2498 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 145ms/step - accuracy: 0.9363 - loss: 0.1651 - val_accuracy: 0.9098 - val_loss: 0.2478 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - accuracy: 0.9436 - loss: 0.1542 - val_accuracy: 0.9038 - val_loss: 0.2527 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 142ms/step - accuracy: 0.9532 - loss: 0.1288 - val_accuracy: 0.9053 - val_loss: 0.2720 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 142ms/step - accuracy: 0.9555 - loss: 0.1270 - val_accuracy: 0.9053 - val_loss: 0.2760 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 141ms/step - accuracy: 0.9584 - loss: 0.1145 - val_accuracy: 0.9098 - val_loss: 0.2775 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - accuracy: 0.9693 - loss: 0.0936 - val_accuracy: 0.9038 - val_loss: 0.2939 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - accuracy: 0.9698 - loss: 0.0798 - val_accuracy: 0.9113 - val_loss: 0.2892 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 143ms/step - accuracy: 0.9698 - loss: 0.0844 - val_accuracy: 0.9113 - val_loss: 0.2887 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 142ms/step - accuracy: 0.9799 - loss: 0.0640 - val_accuracy: 0.9068 - val_loss: 0.2987 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 141ms/step - accuracy: 0.9812 - loss: 0.0677 - val_accuracy: 0.9128 - val_loss: 0.2917 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 141ms/step - accuracy: 0.9742 - loss: 0.0736 - val_accuracy: 0.9158 - val_loss: 0.2992 - learning_rate: 3.1250e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 145ms/step - accuracy: 0.9832 - loss: 0.0581 - val_accuracy: 0.9158 - val_loss: 0.2964 - learning_rate: 3.1250e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 143ms/step - accuracy: 0.9783 - loss: 0.0668 - val_accuracy: 0.9098 - val_loss: 0.2944 - learning_rate: 3.1250e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 142ms/step - accuracy: 0.9812 - loss: 0.0611 - val_accuracy: 0.9143 - val_loss: 0.2971 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 144ms/step - accuracy: 0.9784 - loss: 0.0667 - val_accuracy: 0.9128 - val_loss: 0.2948 - learning_rate: 1.5625e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 142ms/step - accuracy: 0.9821 - loss: 0.0582 - val_accuracy: 0.9083 - val_loss: 0.2961 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 144ms/step - accuracy: 0.9750 - loss: 0.0677 - val_accuracy: 0.9128 - val_loss: 0.2952 - learning_rate: 7.8125e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - accuracy: 0.9796 - loss: 0.0638 - val_accuracy: 0.9113 - val_loss: 0.2968 - learning_rate: 7.8125e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 146ms/step - accuracy: 0.9818 - loss: 0.0560 - val_accuracy: 0.9143 - val_loss: 0.2963 - learning_rate: 7.8125e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - accuracy: 0.9840 - loss: 0.0520 - val_accuracy: 0.9113 - val_loss: 0.2954 - learning_rate: 3.9063e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.9770 - loss: 0.0582 - val_accuracy: 0.9113 - val_loss: 0.2960 - learning_rate: 3.9063e-06\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       418\n",
      "           1       0.87      0.88      0.88       247\n",
      "\n",
      "    accuracy                           0.91       665\n",
      "   macro avg       0.90      0.90      0.90       665\n",
      "weighted avg       0.91      0.91      0.91       665\n",
      "\n",
      "Accuracy: 0.9067669172932331\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 121\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred))\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# LIME Explanation\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Modify LIME explanation\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mLimeTabularExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_combined\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_combined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLung_Disease\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscretize_continuous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    126\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Function to make LIME-compatible predictions\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlime_predict_fn\u001b[39m(x):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lime\\lime_tabular.py:215\u001b[0m, in \u001b[0;36mLimeTabularExplainer.__init__\u001b[1;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[0;32m    209\u001b[0m     discretizer \u001b[38;5;241m=\u001b[39m StatsDiscretizer(training_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_features,\n\u001b[0;32m    210\u001b[0m                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, labels\u001b[38;5;241m=\u001b[39mtraining_labels,\n\u001b[0;32m    211\u001b[0m                                    data_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_data_stats,\n\u001b[0;32m    212\u001b[0m                                    random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discretizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquartile\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscretizer \u001b[38;5;241m=\u001b[39m \u001b[43mQuartileDiscretizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m discretizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecile\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscretizer \u001b[38;5;241m=\u001b[39m DecileDiscretizer(\n\u001b[0;32m    221\u001b[0m             training_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_features,\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, labels\u001b[38;5;241m=\u001b[39mtraining_labels,\n\u001b[0;32m    223\u001b[0m             random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lime\\discretize.py:178\u001b[0m, in \u001b[0;36mQuartileDiscretizer.__init__\u001b[1;34m(self, data, categorical_features, feature_names, labels, random_state)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, categorical_features, feature_names, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 178\u001b[0m     \u001b[43mBaseDiscretizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lime\\discretize.py:83\u001b[0m, in \u001b[0;36mBaseDiscretizer.__init__\u001b[1;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_bins \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     82\u001b[0m     selection \u001b[38;5;241m=\u001b[39m data[discretized \u001b[38;5;241m==\u001b[39m x, feature]\n\u001b[1;32m---> 83\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(selection) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans[feature]\u001b[38;5;241m.\u001b[39mappend(mean)\n\u001b[0;32m     85\u001b[0m     std \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(selection) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstd(selection)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:118\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    115\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    116\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Data Loading with Augmentation\n",
    "base_path = '../Database/'\n",
    "data, labels = [], []\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2], fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load Data\n",
    "def load_images_from_folder(folder, label):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "load_images_from_folder(\"Normal\", \"Normal\")\n",
    "for folder in [\"Lung_Opacity\", \"Viral Pneumonia\"]:\n",
    "    load_images_from_folder(folder, \"Lung_Disease\")\n",
    "\n",
    "data = np.array(data).astype('float32') / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "\n",
    "# Extract HOG Features\n",
    "def extract_hog_features(images):\n",
    "    return np.array([hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2), visualize=False) for img in images])\n",
    "\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_test_hog = extract_hog_features(X_test)\n",
    "\n",
    "# Combine CNN + HOG Features\n",
    "X_train_combined = np.hstack((X_train.reshape(X_train.shape[0], -1), X_train_hog))\n",
    "X_test_combined = np.hstack((X_test.reshape(X_test.shape[0], -1), X_test_hog))\n",
    "\n",
    "# Handle Imbalance Using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_combined, y_train = smote.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "# Custom Dense Model (for combined features)\n",
    "def create_custom_dense_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(input_shape,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model Initialization\n",
    "model = create_custom_dense_model(X_train_combined.shape[1])\n",
    "\n",
    "# Learning Rate Scheduler & Early Stopping\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_combined, y_train, validation_data=(X_test_combined, y_test),\n",
    "                    epochs=50, callbacks=[lr_scheduler, early_stopping], batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = (model.predict(X_test_combined) > 0.55).astype(\"int32\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# LIME Explanation\n",
    "# Modify LIME explanation\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_train_combined,\n",
    "    feature_names=[\"Feature \" + str(i) for i in range(X_train_combined.shape[1])],\n",
    "    class_names=[\"Normal\", \"Lung_Disease\"],\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# Function to make LIME-compatible predictions\n",
    "def lime_predict_fn(x):\n",
    "    preds = model.predict(x)  # Model returns shape (n_samples, 1)\n",
    "    return np.hstack([1 - preds, preds])  # Convert to shape (n_samples, 2)\n",
    "\n",
    "# Explain a test instance\n",
    "exp = explainer.explain_instance(X_test_combined[0], lime_predict_fn, num_features=10)\n",
    "\n",
    "# Show explanation\n",
    "exp.as_pyplot_figure()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training & Validation Graphs\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d48cb-8057-436b-865b-a9487ce4cfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
