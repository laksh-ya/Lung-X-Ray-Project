{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2310a-6587-4434-be26-607e978070fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.combine import SMOTETomek\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Base path and augmentation config\n",
    "base_path = '../Database/'\n",
    "data, labels = [], []\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2], fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load & augment images manually before HOG extraction\n",
    "def load_images_from_folder(folder, label, augment_count=3):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "        # Augment\n",
    "        img_rgb = np.stack([img] * 3, axis=-1)  # Grayscale to RGB\n",
    "        img_rgb = np.expand_dims(img_rgb, axis=0)\n",
    "        aug_iter = data_gen.flow(img_rgb, batch_size=1)\n",
    "        for _ in range(augment_count):\n",
    "            aug_img = next(aug_iter)[0][:, :, 0]  #   # Convert back to grayscale\n",
    "            data.append(aug_img)\n",
    "            labels.append(label)\n",
    "\n",
    "# Load all categories\n",
    "load_images_from_folder(\"Normal\", \"Normal\")\n",
    "for folder in [\"Lung_Opacity\", \"Viral Pneumonia\"]:\n",
    "    load_images_from_folder(folder, \"Lung_Disease\")\n",
    "\n",
    "data = np.array(data).astype('float32') / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "\n",
    "# HOG feature extraction\n",
    "def extract_hog_features(images):\n",
    "    return np.array([hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2), visualize=False) for img in images])\n",
    "\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_test_hog = extract_hog_features(X_test)\n",
    "\n",
    "# Combine HOG + Raw Pixel Features\n",
    "X_train_combined = np.hstack((X_train.reshape(X_train.shape[0], -1), X_train_hog))\n",
    "X_test_combined = np.hstack((X_test.reshape(X_test.shape[0], -1), X_test_hog))\n",
    "\n",
    "# SMOTETomek for class balance\n",
    "smote = SMOTETomek(random_state=42)\n",
    "X_train_combined, y_train = smote.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_test_combined = scaler.transform(X_test_combined)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_combined = pca.fit_transform(X_train_combined)\n",
    "X_test_combined = pca.transform(X_test_combined)\n",
    "\n",
    "# Dense neural network\n",
    "def create_custom_dense_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(input_shape,), kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_custom_dense_model(X_train_combined.shape[1])\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Add Gaussian noise to features\n",
    "noise_factor = 0.05\n",
    "X_train_noisy = X_train_combined + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train_combined.shape)\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "\n",
    "# Training\n",
    "history = model.fit(X_train_noisy, y_train, validation_data=(X_test_combined, y_test),\n",
    "                    epochs=50, callbacks=[lr_scheduler, early_stopping], batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = (model.predict(X_test_combined) > 0.55).astype(\"int32\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# LIME Explainability\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_train_combined,\n",
    "    feature_names=[\"Feature \" + str(i) for i in range(X_train_combined.shape[1])],\n",
    "    class_names=[\"Normal\", \"Lung_Disease\"],\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "def lime_predict_fn(x):\n",
    "    preds = model.predict(x)\n",
    "    return np.hstack([1 - preds, preds])\n",
    "\n",
    "exp = explainer.explain_instance(X_test_combined[0], lime_predict_fn, num_features=10)\n",
    "exp.as_pyplot_figure()\n",
    "plt.show()\n",
    "\n",
    "# Plotting accuracy/loss\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy', color='red')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss', color='red')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665402d-358e-475b-b3d2-ed36d372b34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
