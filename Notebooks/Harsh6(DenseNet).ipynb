{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f887457-0290-4132-b482-041b62d1921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.7693 - loss: 0.5098 - val_accuracy: 0.8316 - val_loss: 2.5639 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 3s/step - accuracy: 0.8853 - loss: 0.2931 - val_accuracy: 0.8632 - val_loss: 1.5110 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.9155 - loss: 0.2136 - val_accuracy: 0.8692 - val_loss: 1.7066 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.9388 - loss: 0.1571 - val_accuracy: 0.8541 - val_loss: 2.1503 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.9540 - loss: 0.1248 - val_accuracy: 0.8511 - val_loss: 2.3973 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m 6/83\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 1s/step - accuracy: 0.9737 - loss: 0.0792"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Input, Concatenate\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Data Loading with Augmentation\n",
    "base_path = '../Database/'\n",
    "data, labels = [], []\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2], fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "load_images_from_folder(\"Normal\", \"Normal\")\n",
    "for folder in [\"Lung_Opacity\", \"Viral Pneumonia\"]:\n",
    "    load_images_from_folder(folder, \"Lung_Disease\")\n",
    "\n",
    "data = np.array(data).astype('float32') / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "\n",
    "# Extract HOG Features\n",
    "def extract_hog_features(images):\n",
    "    return np.array([hog(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), orientations=9, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2), visualize=False) for img in images])\n",
    "\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_test_hog = extract_hog_features(X_test)\n",
    "\n",
    "# Handle Imbalance Using SMOTE\n",
    "# Handle Imbalance Using SMOTE (Apply to Combined Features)\n",
    "X_train_combined = np.hstack((X_train.reshape(X_train.shape[0], -1), X_train_hog))\n",
    "\n",
    "# Apply SMOTE to the Combined Features\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "# Split the balanced data back into CNN and HOG parts\n",
    "X_train_cnn_balanced = X_train_balanced[:, :X_train.size // X_train.shape[0]].reshape(-1, 128, 128, 1)\n",
    "X_train_hog_balanced = X_train_balanced[:, X_train.size // X_train.shape[0]:]\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_hog_balanced = scaler.fit_transform(X_train_hog_balanced)\n",
    "X_test_hog = scaler.transform(X_test_hog)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_hog = scaler.fit_transform(X_train_hog)\n",
    "X_test_hog = scaler.transform(X_test_hog)\n",
    "\n",
    "# Build DenseNet Model\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "# Feature extraction from DenseNet\n",
    "cnn_input = Input(shape=(128, 128, 3))\n",
    "cnn_features = base_model(cnn_input, training=False)\n",
    "cnn_features = Flatten()(cnn_features)\n",
    "cnn_features = Dense(256, activation='relu')(cnn_features)\n",
    "cnn_features = BatchNormalization()(cnn_features)\n",
    "cnn_features = Dropout(0.5)(cnn_features)\n",
    "\n",
    "# HOG Input Layer\n",
    "hog_input = Input(shape=(X_train_hog.shape[1],))\n",
    "hog_features = Dense(128, activation='relu')(hog_input)\n",
    "hog_features = BatchNormalization()(hog_features)\n",
    "hog_features = Dropout(0.5)(hog_features)\n",
    "\n",
    "# Concatenate CNN and HOG Features\n",
    "combined_features = Concatenate()([cnn_features, hog_features])\n",
    "final_dense = Dense(64, activation='relu')(combined_features)\n",
    "final_dense = BatchNormalization()(final_dense)\n",
    "final_dense = Dropout(0.4)(final_dense)\n",
    "output = Dense(1, activation='sigmoid')(final_dense)\n",
    "\n",
    "# Create Model\n",
    "model = Model(inputs=[cnn_input, hog_input], outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning Rate Scheduler & Early Stopping\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([X_train, X_train_hog], y_train, validation_data=([X_test, X_test_hog], y_test),\n",
    "                    epochs=50, callbacks=[lr_scheduler, early_stopping], batch_size=32)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = (model.predict([X_test, X_test_hog]) > 0.55).astype(\"int32\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d08cd1-e93e-4622-b0db-f902e3c52647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
